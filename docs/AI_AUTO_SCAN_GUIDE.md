# ğŸš€ AI-Enhanced Auto Scan ê°€ì´ë“œ

## ê°œìš”

ì´ ì‹œìŠ¤í…œì€ **ê¸°ì¡´ íŒ¨í„´ ë¶„ì„ + AI ì½”ë“œ í’ˆì§ˆ ë¶„ì„**ì„ í†µí•©í•˜ì—¬ ëª¨ë“  Nuxt í”„ë¡œì íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ìŠ¤ìº”í•˜ê³  BestCaseë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

## ì£¼ìš” ê¸°ëŠ¥

### 1. ìë™ í”„ë¡œì íŠ¸ íƒìƒ‰
- `D:/01.Work/01.Projects` í•˜ìœ„ ëª¨ë“  Nuxt í”„ë¡œì íŠ¸ ìë™ ê°ì§€
- 2ë‹¨ê³„ ê¹Šì´ê¹Œì§€ íƒìƒ‰ (ì˜ˆ: `50.dktechin/frontend`)
- package.jsonì—ì„œ Nuxt ì˜ì¡´ì„± í™•ì¸

### 2. AI ì½”ë“œ í’ˆì§ˆ ë¶„ì„
- **LLM ëª¨ë¸:** qwen2.5-coder:1.5b (GPU ê°€ì†)
- **ë³‘ë ¬ ì²˜ë¦¬:** 3ê°œ íŒŒì¼ ë™ì‹œ ë¶„ì„
- **ë¶„ì„ ëŒ€ìƒ:** composables + pages (ìµœëŒ€ 20íŒŒì¼)
- **ë¶„ì„ í•­ëª©:**
  - Type Safety (0-30ì )
  - Error Handling (0-30ì )
  - Best Practices (0-40ì )

### 3. íŒ¨í„´ ë¶„ì„ (ê¸°ì¡´)
- **API ê°ì§€:** OpenAPI, gRPC
- **ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©ëŸ‰:** CommonTable, CommonButton ë“±
- **Composable ì‚¬ìš©ëŸ‰:** usePaging, useBackendClient ë“±
- **Tailwind ë¶„ì„:** ì„¤ì • íŒŒì¼, ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤

### 4. í†µí•© ì ìˆ˜ ê³„ì‚°
```
ìµœì¢… ì ìˆ˜ = AI ì ìˆ˜ (60%) + íŒ¨í„´ ì ìˆ˜ (40%)

Tier ë“±ê¸‰:
- S: 80ì  ì´ìƒ
- A: 60-79ì 
- B: 40-59ì 
- C: 20-39ì 
- D: 20ì  ë¯¸ë§Œ
```

## ì‚¬ìš©ë²•

### ìˆ˜ë™ ì‹¤í–‰

```bash
# ì „ì²´ í”„ë¡œì íŠ¸ AI ë¶„ì„ (ê¶Œì¥)
yarn scan:auto-ai

# ê¸°ì¡´ ë°©ì‹ (AI ì—†ìŒ)
yarn scan:auto

# ë‹¨ì¼ í”„ë¡œì íŠ¸ AI í…ŒìŠ¤íŠ¸
yarn test:ai
```

### ìë™ ì‹¤í–‰ (í¬ë¡  ìŠ¤ì¼€ì¤„ëŸ¬)

Docker ì»¨í…Œì´ë„ˆê°€ **6ì‹œê°„ë§ˆë‹¤** ìë™ìœ¼ë¡œ ìŠ¤ìº”:

```bash
# Docker Composeë¡œ ì‹œì‘
docker-compose -f docker-compose.ai.yml up -d

# í¬ë¡  ë¡œê·¸ í™•ì¸
docker logs bestcase-cron-scheduler -f

# ìˆ˜ë™ìœ¼ë¡œ í¬ë¡  ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
docker exec bestcase-cron-scheduler /app/cron-scan.sh
```

**í¬ë¡  ìŠ¤ì¼€ì¤„:** `0 */6 * * *` (ë§¤ 6ì‹œê°„)

## ì‹œìŠ¤í…œ êµ¬ì„±

### 1. Ollama LLM ì„œë²„
- **GPU:** NVIDIA GTX 1060 6GB (ì „ì²´ í™œìš©)
- **ë©”ëª¨ë¦¬:** 24GB RAM í• ë‹¹
- **ëª¨ë¸:** qwen2.5-coder:1.5b (1.0GB)
- **í¬íŠ¸:** 11434

### 2. MCP ì„œë²„
- **ë©”ëª¨ë¦¬:** 8GB RAM í• ë‹¹
- **ì—­í• :** filesystem, bestcase API ì œê³µ
- **ë³¼ë¥¨:** D:/01.Work/01.Projects (ì½ê¸° ì „ìš©)

### 3. í¬ë¡  ìŠ¤ì¼€ì¤„ëŸ¬
- **ë©”ëª¨ë¦¬:** 4GB RAM í• ë‹¹
- **ìŠ¤ì¼€ì¤„:** 6ì‹œê°„ë§ˆë‹¤ ìë™ ì‹¤í–‰
- **ë³¼ë¥¨:** D:/01.Work/01.Projects (ì½ê¸°/ì“°ê¸°)

## í™˜ê²½ ë³€ìˆ˜

```bash
# Ollama ì„¤ì •
OLLAMA_URL=http://ollama:11434
LLM_MODEL=qwen2.5-coder:1.5b  # ë˜ëŠ” qwen2.5-coder:7b

# ë³‘ë ¬ ì²˜ë¦¬
CONCURRENCY=3  # 1~5 (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì ˆ)

# ê²½ë¡œ ì„¤ì •
PROJECTS_PATH=/projects
BESTCASE_STORAGE_PATH=/projects/.bestcases
```

## ì„±ëŠ¥

### AI ë¶„ì„ ì†ë„ (1.5B ëª¨ë¸, 3ê°œ ë³‘ë ¬)
- **10íŒŒì¼:** ì•½ 35ì´ˆ (3.5ì´ˆ/íŒŒì¼)
- **20íŒŒì¼:** ì•½ 70ì´ˆ
- **ì²˜ë¦¬ëŸ‰:** 0.29 íŒŒì¼/ì´ˆ

### ì „ì²´ ìŠ¤ìº” ì˜ˆìƒ ì‹œê°„
- **66ê°œ í”„ë¡œì íŠ¸ (í‰ê·  15íŒŒì¼):** ì•½ 60ë¶„
- **í¬ë¡  ì£¼ê¸°:** 6ì‹œê°„ë§ˆë‹¤ (ì¶©ë¶„í•œ ê°„ê²©)

## BestCase ì €ì¥ í˜•ì‹

```json
{
  "id": "project-name-auto-scan-ai-1699334400000",
  "projectName": "50.dktechin/frontend",
  "category": "auto-scan-ai",
  "description": "í”„ë¡œì íŠ¸ëª… AI-Enhanced Scan (Tier A, Score: 72/100)",
  "patterns": {
    "scores": {
      "final": 72,
      "pattern": 65,
      "api": 40,
      "component": 90,
      "tier": "A"
    },
    "aiAnalysis": {
      "averageScore": 75.0,
      "totalFiles": 10,
      "topFiles": [...],
      "excellentSnippets": [...],
      "detailedResults": [...]
    },
    "stats": { ... },
    "apiInfo": { ... },
    "componentUsage": { ... }
  },
  "tags": ["auto-scan", "ai-analysis", "A", "nuxt 3", "2025-11-07"]
}
```

## ìš°ìˆ˜ ì½”ë“œ ë°œê²¬

AIê°€ **85ì  ì´ìƒ ìŠ¤ë‹ˆí«**ì„ ìë™ìœ¼ë¡œ ì¶”ì¶œ:

```json
{
  "excellentSnippets": [
    {
      "filePath": "composables/grpc.ts",
      "score": 95,
      "reason": "Perfect error interceptor implementation",
      "category": "error-handling"
    }
  ]
}
```

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Ollama ì„œë²„ ì‘ë‹µ ì—†ìŒ
```bash
# Ollama ì¬ì‹œì‘
docker restart ollama-code-analyzer

# ëª¨ë¸ í™•ì¸
docker exec ollama-code-analyzer ollama list

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
docker exec ollama-code-analyzer ollama pull qwen2.5-coder:1.5b
```

### GPU ë¯¸ì‚¬ìš©
```bash
# GPU í™•ì¸
docker exec ollama-code-analyzer nvidia-smi

# Docker Compose ì¬ì‹œì‘
docker-compose -f docker-compose.ai.yml down
docker-compose -f docker-compose.ai.yml up -d
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# WSL2 ë©”ëª¨ë¦¬ í™•ì¸
wsl -e sh -c "free -h"

# .wslconfig ìˆ˜ì • (C:\Users\ì‚¬ìš©ìëª…\.wslconfig)
[wsl2]
memory=32GB
processors=8
```

### í¬ë¡  ì‘ë™ ì•ˆí•¨
```bash
# í¬ë¡  ë¡œê·¸ í™•ì¸
docker logs bestcase-cron-scheduler

# crontab í™•ì¸
docker exec bestcase-cron-scheduler crontab -l

# ìˆ˜ë™ ì‹¤í–‰
docker exec bestcase-cron-scheduler /app/cron-scan.sh
```

## ì„±ëŠ¥ ìµœì í™”

### GPU ì‚¬ìš© ì‹œ (ê¶Œì¥)
- **ëª¨ë¸:** qwen2.5-coder:7b
- **ë³‘ë ¬:** 1 (Ollama ë™ì‹œì„± ì œí•œ)
- **ì†ë„:** ëŠë¦¬ì§€ë§Œ ì •í™•ë„ ë†’ìŒ

### CPU ì‚¬ìš© ì‹œ
- **ëª¨ë¸:** qwen2.5-coder:1.5b
- **ë³‘ë ¬:** 3~5
- **ì†ë„:** ë¹ ë¥´ê³  ì•ˆì •ì 

### ëŒ€ëŸ‰ ìŠ¤ìº”
- **ë¶„ì„ íŒŒì¼ ìˆ˜ ì œí•œ:** composables ì „ì²´ + pages 5ê°œ
- **íƒ€ì„ì•„ì›ƒ:** 60ì´ˆ (í”„ë¡œì íŠ¸ë‹¹)
- **ë°°ì¹˜ ì²˜ë¦¬:** 3ê°œì”© ë³‘ë ¬

## ë¡œê·¸ í™•ì¸

```bash
# ì „ì²´ ë¡œê·¸
yarn scan:auto-ai 2>&1 | tee scan-log.txt

# Ollama ë¡œê·¸
docker logs ollama-code-analyzer --tail 50

# í¬ë¡  ë¡œê·¸
docker exec bestcase-cron-scheduler tail -f /var/log/cron.log
```

## ë‹¤ìŒ ë‹¨ê³„

1. **BestCase ëª©ë¡ ì¡°íšŒ:** `yarn test:scores`
2. **ìš°ìˆ˜ ì½”ë“œ ì¶”ì¶œ:** 85ì  ì´ìƒ ìŠ¤ë‹ˆí« ìë™ ìˆ˜ì§‘
3. **ëŒ€ì‹œë³´ë“œ:** í”„ë¡œì íŠ¸ë³„ Tier ì‹œê°í™”
4. **ì•Œë¦¼:** Slack/Discord í†µí•© (Tier S í”„ë¡œì íŠ¸ ì•Œë¦¼)
