#!/bin/bash

# Ollama ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸
echo "ğŸš€ Initializing Ollama with code analysis models..."

# Ollama ì»¨í…Œì´ë„ˆê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°
echo "â³ Waiting for Ollama to be ready..."
until docker exec ollama-code-analyzer ollama list > /dev/null 2>&1; do
  sleep 2
done

echo "âœ… Ollama is ready!"

# ì½”ë“œ ë¶„ì„ìš© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
echo ""
echo "ğŸ“¥ Downloading code analysis models..."
echo "   This may take 10-20 minutes depending on your internet speed."
echo ""

# qwen2.5-coder:7b (ì¶”ì²œ - ë¹ ë¥´ê³  ì •í™•)
echo "1ï¸âƒ£ Downloading qwen2.5-coder:7b (4.7GB)..."
docker exec ollama-code-analyzer ollama pull qwen2.5-coder:7b

# deepseek-coder:6.7b (ëŒ€ì•ˆ - ì½”ë“œ ë¶„ì„ íŠ¹í™”)
echo ""
echo "2ï¸âƒ£ Downloading deepseek-coder:6.7b (3.8GB)..."
docker exec ollama-code-analyzer ollama pull deepseek-coder:6.7b

# codellama:7b (ëŒ€ì•ˆ - Metaì˜ ì½”ë“œ LLM)
echo ""
echo "3ï¸âƒ£ Downloading codellama:7b (3.8GB)..."
docker exec ollama-code-analyzer ollama pull codellama:7b

echo ""
echo "âœ… All models downloaded successfully!"
echo ""
echo "ğŸ“Š Installed models:"
docker exec ollama-code-analyzer ollama list

echo ""
echo "ğŸ‰ Ollama initialization complete!"
echo ""
echo "You can now use the following models:"
echo "  - qwen2.5-coder:7b    (Recommended)"
echo "  - deepseek-coder:6.7b (Code-specialized)"
echo "  - codellama:7b        (Meta's LLM)"
echo ""
echo "Test with: docker exec ollama-code-analyzer ollama run qwen2.5-coder:7b"
