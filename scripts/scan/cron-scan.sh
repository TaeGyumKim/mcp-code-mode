#!/bin/sh
# ì •ê¸° AI ìŠ¤ìº” ìŠ¤í¬ë¦½íŠ¸ (Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ì‹¤í–‰)
# ë§¤ì£¼ ì¼ìš”ì¼ì— ì‹¤í–‰ë¨

echo "========================================="
echo "ğŸ¤– Weekly BestCase AI Scan"
echo "ğŸ“… $(date)"
echo "========================================="

cd /app

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export LLM_MODEL="${LLM_MODEL:-qwen2.5-coder:7b}"
export CONCURRENCY="${CONCURRENCY:-2}"

# Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
if ! curl -sf http://ollama:11434/api/tags > /dev/null 2>&1; then
  echo "âš ï¸ Ollama server not available, skipping AI scan"
  echo "Please check Ollama container status"
  exit 1
fi

echo "âœ… Ollama available, starting weekly scan process"
echo "ğŸ§  LLM Model: $LLM_MODEL"
echo "âš¡ Concurrency: $CONCURRENCY"
echo ""

# AI ê¸°ë°˜ ìë™ ìŠ¤ìº” ì‹¤í–‰
echo "ğŸ” Running AI-enhanced scan..."
node /app/scripts/dist/scan/auto-scan-projects-ai.js

echo ""
echo "âœ¨ Weekly AI scan completed at $(date)"
echo ""
