version: '3.8'

services:
  # Ollama LLM Server for Code Analysis with GPU
  ollama:
    image: ollama/ollama:latest
    container_name: ollama-code-analyzer
    volumes:
      - ollama-models:/root/.ollama
    ports:
      - "11434:11434"
    restart: unless-stopped
    networks:
      - mcp-network
    # GPU ÌôúÏÑ±Ìôî (NVIDIA GPUÍ∞Ä ÏûàÎäî Í≤ΩÏö∞)
    # ÏóÜÏúºÎ©¥ CPUÎ°ú ÎèôÏûë
    runtime: nvidia
    deploy:
      resources:
        limits:
          memory: 24G
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['1']
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - OLLAMA_NUM_PARALLEL=3
      - OLLAMA_MAX_LOADED_MODELS=1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MCP Code Mode Server
  mcp-code-mode:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mcp-code-mode-server
    ports:
      - "3000:3000"
    volumes:
      - ${HOST_PROJECTS_PATH}:/projects
    environment:
      - NODE_ENV=${NODE_ENV:-production}
      - HOST_PROJECTS_PATH=${HOST_PROJECTS_PATH}  # Í≤ΩÎ°ú Î≥ÄÌôòÏóê ÌïÑÏöî
      - PROJECTS_PATH=${PROJECTS_PATH:-/projects}
      - BESTCASE_STORAGE_PATH=${BESTCASE_STORAGE_PATH:-/projects/.bestcases}
      - OLLAMA_URL=${OLLAMA_URL:-http://ollama:11434}
      - OLLAMA_HOST=${OLLAMA_HOST:-http://ollama:11434}
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - LLM_MODEL=${LLM_MODEL:-qwen2.5-coder:7b}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-qwen2.5-coder:7b}
      - CONCURRENCY=${CONCURRENCY:-2}
      - DESIGN_SYSTEMS=${DESIGN_SYSTEMS:-openerd-nuxt3,element-plus,vuetify}
      # RAG ÏûÑÎ≤†Îî© ÏÑ§Ï†ï
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-nomic-embed-text}
      - GENERATE_EMBEDDINGS=${GENERATE_EMBEDDINGS:-true}
      # BestCase ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò ÏÑ§Ï†ï (ÏãúÏûë Ïãú ÏûêÎèô Ï≤¥ÌÅ¨)
      - AUTO_MIGRATE_ON_STARTUP=${AUTO_MIGRATE_ON_STARTUP:-true}
      - REANALYZE_OLD_VERSIONS=${REANALYZE_OLD_VERSIONS:-false}
      # BestCase Í≤ÄÏ¶ù Î∞è ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò ÏÑ§Ï†ï
      - BESTCASE_RETENTION_DAYS=${BESTCASE_RETENTION_DAYS:-90}
      - SKIP_BESTCASE_VALIDATION=${SKIP_BESTCASE_VALIDATION:-false}
      - BESTCASE_BACKUP_ON_VALIDATE=${BESTCASE_BACKUP_ON_VALIDATE:-false}
      - BESTCASE_MIGRATE_OLD_FORMAT=${BESTCASE_MIGRATE_OLD_FORMAT:-true}
    deploy:
      resources:
        limits:
          memory: 8G
    restart: unless-stopped
    depends_on:
      - ollama
    networks:
      - mcp-network
    # Ïª®ÌÖåÏù¥ÎÑà Ïú†ÏßÄ (VSCodeÏóêÏÑú docker execÎ°ú mcp-stdio-server.js Ïã§Ìñâ)
    command: tail -f /dev/null
    healthcheck:
      test: ["CMD", "test", "-f", "/app/mcp-stdio-server.js"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Local Package Analyzer (ÎèÖÎ¶Ω ÏÑúÎπÑÏä§)
  local-package-analyzer:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: local-package-analyzer
    volumes:
      - ${HOST_PROJECTS_PATH}:/projects
      - ./.mcp:/app/.mcp  # Î°úÏª¨ Ìå®ÌÇ§ÏßÄ ÏÑ§Ï†ï ÌååÏùº
    environment:
      - NODE_ENV=${NODE_ENV:-production}
      - PROJECTS_PATH=${PROJECTS_PATH:-/projects}
      - OLLAMA_URL=${OLLAMA_URL:-http://ollama:11434}
      - LLM_MODEL=${LLM_MODEL:-qwen2.5-coder:7b}
      - ANALYSIS_MODE=${LOCAL_PACKAGE_ANALYSIS_MODE:-unanalyzed}  # all | unanalyzed | force
      - LOG_ERRORS=true
      # Git Ïù∏Ï¶ù (ÌïÑÏöîÏãú)
      - GIT_USERNAME=${GIT_USERNAME:-}
      - GIT_PASSWORD=${GIT_PASSWORD:-}
      - GIT_TOKEN=${GIT_TOKEN:-}
    deploy:
      resources:
        limits:
          memory: 6G
    restart: unless-stopped
    depends_on:
      - ollama
    networks:
      - mcp-network
    entrypoint: /bin/sh
    command: >
      -c "
      echo 'üîß Local Package Analyzer starting...' &&
      mkdir -p /var/log &&
      touch /var/log/local-packages.log &&
      echo 'üìÖ Cron schedule: Daily at 00:00 (midnight) for unanalyzed packages' &&
      echo 'üìÖ Cron schedule: Weekly on Sunday at 03:00 AM for re-analysis (all packages)' &&
      echo '0 0 * * * ANALYSIS_MODE=unanalyzed tsx /app/scripts/analyze-local-packages.ts >> /var/log/local-packages.log 2>&1' | crontab - &&
      echo '0 3 * * 0 ANALYSIS_MODE=all tsx /app/scripts/analyze-local-packages.ts >> /var/log/local-packages.log 2>&1' | crontab - &&
      cron &&
      echo '‚úÖ Local package analyzer ready' &&
      echo '   - Daily scan (unanalyzed): 00:00' &&
      echo '   - Weekly re-scan (all): Sunday 03:00' &&
      tail -f /var/log/local-packages.log
      "

  # Cron Scheduler for Auto Scan (Weekly)
  cron-scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: bestcase-cron-scheduler
    volumes:
      - ${HOST_PROJECTS_PATH}:/projects
    environment:
      - NODE_ENV=${NODE_ENV:-production}
      - PROJECTS_PATH=${PROJECTS_PATH:-/projects}
      - BESTCASE_STORAGE_PATH=${BESTCASE_STORAGE_PATH:-/projects/.bestcases}
      - OLLAMA_URL=${OLLAMA_URL:-http://ollama:11434}
      - LLM_MODEL=${LLM_MODEL:-qwen2.5-coder:7b}
      - CONCURRENCY=${CONCURRENCY:-2}
      - DESIGN_SYSTEMS=${DESIGN_SYSTEMS:-openerd-nuxt3,element-plus,vuetify}
      # RAG ÏûÑÎ≤†Îî© ÏÑ§Ï†ï
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-nomic-embed-text}
      - GENERATE_EMBEDDINGS=${GENERATE_EMBEDDINGS:-true}
      # BestCase ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò ÏÑ§Ï†ï (ÏãúÏûë Ïãú ÏûêÎèô Ï≤¥ÌÅ¨ Î∞è Ïû¨Î∂ÑÏÑù)
      - AUTO_MIGRATE_ON_STARTUP=${AUTO_MIGRATE_ON_STARTUP:-true}
      - REANALYZE_OLD_VERSIONS=${REANALYZE_OLD_VERSIONS:-true}
      - MAX_REANALYZE_COUNT=${MAX_REANALYZE_COUNT:-10}
      # BestCase Í≤ÄÏ¶ù Î∞è ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò ÏÑ§Ï†ï
      - BESTCASE_RETENTION_DAYS=${BESTCASE_RETENTION_DAYS:-90}
      - SKIP_BESTCASE_VALIDATION=${SKIP_BESTCASE_VALIDATION:-false}
      - BESTCASE_BACKUP_ON_VALIDATE=${BESTCASE_BACKUP_ON_VALIDATE:-false}
      - BESTCASE_MIGRATE_OLD_FORMAT=${BESTCASE_MIGRATE_OLD_FORMAT:-true}
    deploy:
      resources:
        limits:
          memory: 4G
    restart: unless-stopped
    depends_on:
      - ollama
      - mcp-code-mode
    networks:
      - mcp-network
    entrypoint: /bin/sh
    command: >
      -c "
      mkdir -p /var/log &&
      touch /var/log/cron.log &&
      chmod +x /app/scripts/scan/init-scan.sh &&
      chmod +x /app/cron-scan.sh &&
      chmod +x /app/docker-entrypoint.sh &&
      echo 'üöÄ Starting cron-scheduler with migration support...' >> /var/log/cron.log &&
      sh /app/scripts/scan/init-scan.sh >> /var/log/cron.log 2>&1 &&
      echo 'üîç Checking BestCase versions on startup...' >> /var/log/cron.log &&
      node --experimental-specifier-resolution=node /app/scripts/dist/scan/migrate-bestcases.js --dry-run >> /var/log/cron.log 2>&1 || true &&
      echo '0 2 * * 0 /app/cron-scan.sh >> /var/log/cron.log 2>&1' | crontab - &&
      cron &&
      echo 'Initialization complete. Weekly cron scheduler started (Every Sunday at 2:00 AM)' &&
      echo 'Next run: Sunday 02:00' &&
      echo 'Features: Auto-migration + Re-analysis enabled' &&
      tail -f /var/log/cron.log
      "

  # Í∞úÎ∞úÏö© ÏÑúÎπÑÏä§ (ÏÑ†ÌÉùÏ†Å)
  mcp-code-mode-dev:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mcp-code-mode-dev
    ports:
      - "3001:3000"
    volumes:
      - .:/app
      - /app/node_modules
      - ${HOST_PROJECTS_PATH}:/projects
    environment:
      - NODE_ENV=development
      - PROJECTS_PATH=${PROJECTS_PATH:-/projects}
      - BESTCASE_STORAGE_PATH=${BESTCASE_STORAGE_PATH:-/projects/.bestcases}
      - OLLAMA_URL=${OLLAMA_URL:-http://ollama:11434}
      - DESIGN_SYSTEMS=${DESIGN_SYSTEMS:-openerd-nuxt3,element-plus,vuetify}
    command: yarn workspace web dev
    depends_on:
      - ollama
    networks:
      - mcp-network
    profiles:
      - dev

networks:
  mcp-network:
    driver: bridge

volumes:
  ollama-models:
    driver: local
